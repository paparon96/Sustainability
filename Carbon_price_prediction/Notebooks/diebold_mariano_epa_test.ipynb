{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to carry out the Diebold-Mariano Equal Predictive Ability test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import scipy.stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newey_west_var_est(loss_differential):\n",
    "    df = pd.DataFrame({'loss':loss_differential})\n",
    "\n",
    "    reg = smf.ols('loss ~ 1',data=df).fit(cov_type='HAC', cov_kwds={'maxlags': 1})\n",
    "\n",
    "    return reg.bse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(x, y):\n",
    "    return (x - y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_epa_test_stat(loss_differential, ld_var):\n",
    "    return np.mean(loss_differential) / np.sqrt(ld_var / len(loss_differential))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_value(significance_level, n):\n",
    "    return scipy.stats.t.ppf(q=1-significance_level, df=n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value(test_stat, n):\n",
    "    return scipy.stats.t.sf(np.abs(test_stat), n-1) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_epa_test(full_model_predictions, control_model_predictions, y_true, alpha):\n",
    "\n",
    "    n = len(full_model_predictions)\n",
    "    \n",
    "    full_model_loss = np.array([squared_error(full_model_predictions[i], y_true[i]) for i in range(n)])\n",
    "    control_model_loss = np.array([squared_error(control_model_predictions[i], y_true[i]) for i in range(n)])\n",
    "    loss_differential = full_model_loss - control_model_loss\n",
    "\n",
    "    ld_var = newey_west_var_est(loss_differential)\n",
    "\n",
    "    test_stat = dm_epa_test_stat(loss_differential, ld_var)\n",
    "\n",
    "    c_val = critical_value(alpha, n-1)\n",
    "\n",
    "    p_val = p_value(test_stat, n)\n",
    "\n",
    "    return test_stat > c_val, p_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants / Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10 # Number of periods\n",
    "alpha = 0.05 # Significance level for the test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_predictions = np.random.normal(size=n)\n",
    "control_model_predictions = np.random.normal(size=n)\n",
    "y_true = np.random.normal(size=n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carry out the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.003923164683899836)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm_epa_test(full_model_predictions, control_model_predictions, y_true, alpha)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_loss = np.array([squared_error(full_model_predictions[i], y_true[i]) for i in range(n)])\n",
    "control_model_loss = np.array([squared_error(control_model_predictions[i], y_true[i]) for i in range(n)])\n",
    "loss_differential = full_model_loss - control_model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.63076361, -0.37546618,  4.13710595, -0.93489127, -1.95766985,\n",
       "        1.649415  ,  0.29445781,  2.50587887,  2.29383309,  1.30011835])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'loss':loss_differential})\n",
    "\n",
    "reg = smf.ols('loss ~ 1',data=df).fit(cov_type='HAC', cov_kwds={'maxlags': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MacBook/opt/anaconda3/envs/mlops-course/lib/python3.8/site-packages/scipy/stats/_stats_py.py:1769: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=10\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>loss</td>       <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Jan 2023</td> <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:45:25</td>     <th>  Log-Likelihood:    </th> <td> -19.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    10</td>      <th>  AIC:               </th> <td>   41.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     9</td>      <th>  BIC:               </th> <td>   41.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     0</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HAC</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    1.0544</td> <td>    0.479</td> <td>    2.202</td> <td> 0.028</td> <td>    0.116</td> <td>    1.993</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.021</td> <th>  Durbin-Watson:     </th> <td>   2.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.990</td> <th>  Jarque-Bera (JB):  </th> <td>   0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.076</td> <th>  Prob(JB):          </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.289</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 1 lags and without small sample correction"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   loss   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                  0.000\n",
       "Method:                 Least Squares   F-statistic:                       nan\n",
       "Date:                Tue, 03 Jan 2023   Prob (F-statistic):                nan\n",
       "Time:                        22:45:25   Log-Likelihood:                -19.606\n",
       "No. Observations:                  10   AIC:                             41.21\n",
       "Df Residuals:                       9   BIC:                             41.51\n",
       "Df Model:                           0                                         \n",
       "Covariance Type:                  HAC                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      1.0544      0.479      2.202      0.028       0.116       1.993\n",
       "==============================================================================\n",
       "Omnibus:                        0.021   Durbin-Watson:                   2.435\n",
       "Prob(Omnibus):                  0.990   Jarque-Bera (JB):                0.220\n",
       "Skew:                          -0.076   Prob(JB):                        0.896\n",
       "Kurtosis:                       2.289   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity and autocorrelation robust (HAC) using 1 lags and without small sample correction\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_var = reg.bse[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat = np.mean(loss_differential) / np.sqrt(ld_var / len(loss_differential))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stat > critical_value(alpha, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64350ad345ca6d0ea13dbd5a2e19ad48babc5c17f2285d647c3fd647776889c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
